---
title: "NBA Early-Career Competition Analysis"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())

# Load packages
library(lme4)
library(dplyr)
library(kableExtra)
library(ggplot2)
library(knitr)
library(plotly)
library(patchwork)
library(tidyr)
library(ggeffects)
library(lmerTest)
library(performance) 
library(splines)
library(purrr)
library(viridis)
library(DHARMa)

set.seed(42)
```

## Introduction

In the NBA, teams often face decisions about how to manage players at the same position. A familiar scenario arises when a team drafts a young, high-potential player despite already having an established player at the same position. This raises the question: **does having a more experienced teammate in the same role limit opportunities for the rookie or sophomore, or shape their early development?**

This project examines **how positional competition during a player's rookie and sophomore seasons influences scoring development over the first five years of their career**. Positional competition is defined as the number of teammates at the same position who have more experience and play comparable minutes to the focal player.

The analysis focuses on NBA lottery picks (drafted 1–14) from 2010–2020. I collected each player's regular-season points per game (`PTS.G`) over their first five seasons. To account for repeated measurements within players, I used a *linear mixed-effects model (LMM)*, which combines fixed effects (overall trends) with random effects (player-specific deviations).

## Overview

The analysis focuses on three core measures:

-   **Rookie-year competition**: Experienced players at the same position during Year 1.

-   **Sophomore-year competition**: Experienced players at the same position during Year 2.

-   **Outcome**: Average points per game (`PTS.G`) across the first five seasons.

#### Methods & Approach

-   [Data Preparation]**:** Collected data with Python (`requests`, `BeautifulSoup`), then cleaned and organized it with `pandas` and `dplyr` in R.

-   [Linear Mixed-Effects Model]**:** Modeled scoring trajectories using fixed effects, player-level random effects, and splines (piecewise polynomial functions) to capture nonlinear growth.

-   [Key Findings](#key-findings-visualizations) & [Visualizations]**:** Evaluated model reliability with robust confidence intervals and diagnostic checks, and visualized effects with coefficient and interaction plots.

##### Modeling Flow Chart

```{mermaid}
flowchart LR
    A[Collect Player Data] --> B[Clean & Merge Data]
    B --> C[Fit Initial LMM]
    C --> D[Check Diagnostics]
    D --> E[Refine Model]
    E --> F[Visualize Results]
    E --> D
```

#### Takeaways

-   Players facing **more competition in their sophomore year tend to have flatter or declining scoring trajectories** after Year 3.

-   **Rookie-year competition** has little effect on growth trajectories but slightly increases baseline scoring.

-   Even after controlling for minutes, usage, efficiency, and team context, early-career competition has a subtle but detectable effect on scoring development.

## Data Preparation

Player and career data were collected through a Python web-scraping pipeline built with the `requests` and `BeautifulSoup` libraries, then cleaned and merged with `pandas` before being imported into R for additional data cleaning and analysis.

Players were evaluated over their first five active NBA seasons, defined as seasons in which they appeared in at least one regular-season game. Seasons with no participation (e.g., due to injury) were excluded from the five-year span. Additionally, to reduce noise from seasons with minimal playing time, seasons where players logged fewer than 15 games were excluded from the analysis.

Additionally, for numerical stability and interpretability, all numeric predictors were centered and standardized prior to entry into the model, with the exception of Career Year, which was centered only.

```{r message=FALSE, warning=FALSE}
#| include: false
# Load data
player_data <- read.csv("data/nba_player_stats.csv", 
                        stringsAsFactors = TRUE, header = TRUE)
```

```{r include=FALSE}
player_data <- player_data %>%
  mutate(CareerYear_c = scale(CareerYear_index,scale=FALSE))
```

## Exploratory Data Analysis (EDA)

Before fitting the mixed model, it's useful to visualize how scoring develops across a player's early career and how it might relate to varying levels of positional competition.

### Points per Game Trajectories

```{r include=FALSE}
# Summarize per player
chart_data <- player_data %>%
  group_by(Player, CareerYear_index) %>%
  summarise(
    PTS.G = mean(PTS.G, na.rm = TRUE),
    poscomp_rookie = first(poscomp_rookie),
    poscomp_soph = first(poscomp_soph),
    .groups = "drop"
  )
# Plot
p <- ggplot(data = chart_data, 
            aes(x = CareerYear_index, y = PTS.G, group = Player))
```

```{r}
#| echo: false
p1 <- ggplot(chart_data, aes(x = CareerYear_index, y = PTS.G, group = Player)) +
  geom_line(aes(color = "Individual Players"), alpha=0.25, show.legend = TRUE) +
  stat_smooth(aes(group=1, color = "Linear Trend"), method = "lm", 
              formula = y ~ x, se = FALSE) +
  stat_summary(aes(group=1, color = "Mean per Year"), geom="point", 
               fun = mean, shape=17, size=3) +
  scale_color_manual(
    name = NULL, 
    values = c("Individual Players" = "gray50", 
               "Linear Trend" = "blue", 
               "Mean per Year" = "black")
    ) +
  theme_bw() +
  labs(
    y = "Points per Game",
    x = "Career Year",
    title = "Early-Career Points per Game Trajectories"
    ) +
  theme(
    plot.title = element_text(hjust=0.5, face="bold", size=16),
    legend.position = "bottom"
    )

ggplotly(p1)
```

-   **Observation**: Average points per game (`PTS.G`) increases slightly over the first five years, but individual trajectories vary considerably, highlighting the need for mixed-effects modeling.

### Grouping by Competition

```{r include=FALSE}
label_data <- chart_data %>% 
  filter(CareerYear_index >= 1) %>%
  group_by(poscomp_rookie) %>%
  summarise(n = n_distinct(Player),
            x = max(CareerYear_index),
            y = max(PTS.G, na.rm = TRUE)) 
```

```{r fig.width=8}
#| echo: false
p + geom_line(aes(color="Individual Players"), alpha=0.15, show.legend = TRUE) + 
  stat_smooth(aes(group=1, color="Linear Trend"),method = "lm", 
              formula = y ~ x) + 
  stat_summary(aes(group=1, color="Mean per Year"), geom = "point", 
               fun = mean, shape=17, size=3) + 
  facet_grid(. ~ as.factor(paste(poscomp_rookie, "Competitors"))) + 
  geom_text(
    data = label_data,
    aes(x=5, y=34, label = paste0("n = ", n)),
    inherit.aes = FALSE,
    hjust=1, vjust=1, size=3, color = "black"
  ) +
  scale_color_manual(
    name = NULL, 
    values = c("Individual Players" = "gray50", 
               "Linear Trend" = "blue", 
               "Mean per Year" = "black")
    ) +
  theme_bw() +
  labs(y = "Points per Game", x = "Career Year",
       title = "Early-Career Points per Game Trajectories",
       subtitle = "Grouped by Rookie-Year Competition Levels") +
  theme(
    plot.title = element_text(hjust=0.5, face = "bold", size=16),
    plot.subtitle = element_text(hjust=0.5, size=12, face = "italic", 
                                 color = "gray40"),
    legend.position = "bottom"
  )
```

-   **Observation**: More rookie-year competitors is associated with slightly lower baseline PTS.G, but growth slopes appear similar across groups. Results for higher competition groups are less stable due to smaller sample sizes (n). The per-year averages may suggest early-career scoring growth is nonlinear.

```{r include=FALSE}
label_data <- chart_data %>%
  filter(CareerYear_index !=1) %>%
  group_by(poscomp_soph) %>%
  summarise(n = n_distinct(Player),
            x = max(CareerYear_index),
            y = max(PTS.G, na.rm = TRUE)) 

p <- ggplot(data = chart_data %>%
         filter(CareerYear_index !=1),
       aes(x = CareerYear_index, y = PTS.G, group = Player))
```

```{r fig.width=8}
#| echo: false
p + geom_line(aes(color="Individual Players"), alpha=0.15, show.legend = TRUE) + 
  stat_smooth(aes(group=1, color="Linear Trend"),method = "lm", 
              formula = y ~ x) + 
  stat_summary(aes(group=1, color="Mean per Year"), geom = "point", 
               fun = mean, shape=17, size=3) + 
  facet_grid(. ~ as.factor(paste(poscomp_soph, "Competitors"))) +
  geom_text(
    data = label_data,
    aes(x=5, y=34, label = paste0("n = ", n)),
    inherit.aes = FALSE,
    hjust=1, vjust=1, size=3, color = "black"
  ) +
  scale_color_manual(
    name = NULL, 
    values = c("Individual Players" = "gray50", 
               "Linear Trend" = "blue", 
               "Mean per Year" = "black")
    ) +
  theme_bw() +
  labs(
    y = "Points per Game", x = "Career Year",
    title = "Early Career Points per Game Trajectories",
    subtitle = "Grouped by Sophomore-Year Competition Levels"
  ) +
  theme(
    plot.title = element_text(hjust=0.5, face = "bold", size=16),
    plot.subtitle = element_text(hjust=0.5, size=12, face = "italic", 
                                 color = "gray40"),
    legend.position = "bottom"
  )
```

-   **Observation**: Players with no sophomore competitors show the highest average `PTS.G`. Slopes vary across groups with no distinguishable relationship between competition and trajectory. As noted earlier, estimates for higher competition groups should be interpreted cautiously, and scoring growth may not be linear within each group.

## Linear Mixed-Effects Model

Having examined rookie- and sophomore-year competition effects descriptively through trajectory plots, the next step is to formally test these relationships using **linear mixed-effects models (LMMs)**.

The purpose of the mixed model is to account for the fact that there are **repeated measures for each player**. A simple linear regression would assume all players share the same error variance, which is unrealistic given that players differ systematically in their scoring trajectories, as the descriptive plots already suggested.

An additional advantage of linear mixed models is their ability to handle unbalanced data. This is particularly relevant here, since not all players in the dataset remain in the league through Year 5.

### Intercept Only Model

As a starting point, I fit a simple **intercept-only model** with random intercepts for players. This baseline model estimates the overall average points per game (`PTS.G`) while capturing how each player deviates from that average.

```{r}
# Fit random intercept model
null_model <- lmer(PTS.G ~ (1 | Player), data = player_data, REML = FALSE)
icc(null_model)
```

The Intraclass Correlation Coefficient (ICC) from this model indicates that roughly **70% of the total variance in points per game is attributable to between-player differences**, providing a strong justification for the mixed-effects approach.

### Variables of Interest

Building on the null model, I included **Career Year** (`CareerYear_c`) as a fixed effect and evaluated whether slopes varied across players. Visualizations of player-level growth suggested some variability. However, once other predictors were added, including Career Year as a random effect did not improve model fit, so it was excluded in the final model.

I then added **positional competition counts**, `poscomp_rookie_c` and `poscomp_soph_c` (for rookie- and sophomore-year competition, respectively), as well as their interactions with Career Year. This allowed for testing whether early-career competition influences scoring levels or short-term growth trajectories.

### Control Variables

To isolate the effects of early-career positional competition, I iteratively added key predictors shown to influence scoring. These included: **minutes per game** (`MP.G_c`), **usage percentage** (`USG_c`), **true shooting** percentage (`TS_c`), **assists per game** (`AST.G_c`), **team pace** (`Team_Pace_c`), and **season effects** (`Season_c`). Diagnostic checks were used throughout to assess model assumptions and detect potential nonlinearities or interactions.

### Transformations and Interactions

Several nonlinearities were included in the model including **polynomial terms** for minutes played (`MP.G_c`), true shooting (`TS_c`), and season (`Season_c`). Additionally, **natural cubic splines** were introduced for Career Year (`CareerYear_c`) to flexibly capture nonlinear scoring trajectories across time without forcing a strict polynomial form.

An interaction between usage percentage and polynomial terms for minutes played was retained in the final model due to theoretical relevance and statistical significance, since playing time may amplify how usage percentage affects points per game. By contrast, an interaction between minutes and true shooting was not included because it introduced violations in residual normality, homoscedasticity, and independence.

### Random Slopes for Player-Level Difference

Domain knowledge suggests that usage rate and true shooting affect scoring differently across players.

Some players convert efficiency (`TS_c`) directly into more points by taking high-value shots, while others take fewer shots or pass on opportunities. Usage (`USG_c`) is the proportion of team possessions ending with a player, but high usage does not always translate to more points; some players may favor low-percentage isolation attempts late in the shot clock, or turn the ball over.

Scatter plots with player-level regression lines (`PTS.G ~ TS_c` and `PTS.G ~ USG_c`) confirmed that both baseline scoring levels (intercepts) and relationships with efficiency and usage (slopes) varied across players. This motivated the use of a **random-effects structure** that allows each player to have their own slopes for `TS_c` and `USG_c`, along with an individual baseline scoring intercept:

```{r echo=FALSE}
quote(PTS.G ~ (1 + TS_c + USG_c || Player))
```

This allows each player to have their own baseline scoring and unique sensitivities to efficiency and usage.

### Final Model

The final mixed-effects model estimates how rookie- and sophomore-year positional competition affects both baseline scoring and scoring growth, while adjusting for player- and team-level controls:

```{r eval=FALSE, echo=TRUE}
### Linear Mixed-Effects Model ###
fit_mixed <- lmer(PTS.G ~ poscomp_rookie_c*ns(CareerYear_c,2) 
                  + poscomp_soph_c*ns(CareerYear_c,2)
                  + Team_Pace_c + AST.G_c 
                  + poly(TS_c,3,raw=TRUE) + poly(Season_c,2,raw=TRUE)
                  + poly(MP.G_c,2,raw=TRUE)*USG_c
                  + (1 + TS_c + USG_c || Player),
                  player_data)
```

```{r}
#| message: false
#| include: false
fit_mixed <- readRDS("output/fit_mixed.rds")
```

This model balances statistical performance and interpretability. It includes both **fixed effects** (competition, efficiency, usage, assists, pace, season) and **random effects** (player-level intercepts with slopes for usage and efficiency). In doing so, it models league-wide scoring trends while accounting for how individual players differ in converting efficiency and usage into points.

## Model Diagnostics

To verify that the final linear mixed-effects model was well-specified, I checked the common assumptions of **linearity**, **homoscedasticity**, **normality**, **independence**, and **multicollinearity**.

### Residuals vs. Fitted Values

```{r fig.height=6, fig.width=6}
#| echo: false
residuals <- resid(fit_mixed,type="pearson") # residuals (errors)
fitted <- fitted(fit_mixed) # fitted values

# Residuals vs Fitted plot 
plot(fitted, residuals,main="Residuals vs Fitted")
abline(h = 0, lty = 2, col = "red")
```

Residuals are scattered around zero with **no strong curvature**, suggesting that the model adequately captures **linearity in the conditional mean** and **variance is reasonably constant** (homoscedasticity).

### Normality of Residuals

```{r}
#| echo: false
qqnorm(residuals)
qqline(residuals, col="red")
```

To assess residual normality, I inspected a Q–Q plot of the standardized residuals. The residuals show **some deviations at the tails**, suggesting they are **not perfectly normally distributed**.

```{r}
#| echo: false
simulationOutput <-  simulateResiduals(fittedModel = fit_mixed, n = 1000)
resid.res <- testResiduals(simulationOutput)
```

To supplement this, I used the DHARMa package, which tests residual uniformity rather than normality. The results indicate that the **residuals are consistent with the expected distribution** under the model, i.e. there is **no evidence of model misspecification or biased inference**.

### Independence

```{r}
#| echo: false
# Checking Temporal Autocorrelation
# Reference: https://aosmith.rbind.io/2018/06/27/uneven-grouped-autocorrelation/

# Creating df of residuals
res_df <- data.frame(
  Player = player_data$Player,
  Year   = player_data$CareerYear_c,
  resid  = residuals(fit_mixed, type = "pearson")
  )

# Handling missing years for players
res_expand <- res_df %>%
  group_by(Player) %>%
  complete(Year = seq(min(Year, na.rm = TRUE),
                      max(Year, na.rm = TRUE),
                      by = 1)) %>%
  ungroup()

max_lag <- 4 
nall <- map_df(1:max_lag, function(L) {
  res_df %>%
    group_by(Player) %>%
    arrange(Player, Year) %>%
    summarise(lag = list(diff(Year, lag = L)), .groups = "drop") %>%
    unnest(lag) %>%
    mutate(lag = L)
  }) %>%
  group_by(lag) %>%
  summarise(n = n(), .groups = "drop")

# Global ACF across all players
acf_vals <- acf(res_expand$resid, lag.max = max_lag, na.action = na.pass, plot = FALSE)

# Normalized confidence interval bands
plot(acf_vals, ci = 0, main = "ACF of Residuals")
lines(1:4,-qnorm(1-.025)/sqrt(nall$n), lty = 2)
lines(1:4, qnorm(1-.025)/sqrt(nall$n), lty = 2)
```

Temporal autocorrelation of residuals was examined to ensure **independence of errors** across career years within players. A slight negative autocorrelation was observed between residuals two years apart (Lag 2), but the overall effect is small and unlikely to bias model estimates.

### Multicollinearity

```{r message=FALSE, warning=FALSE}
#| include: false
diagnostic_plots <- plot(check_model(fit_mixed, size_title=24, size_axis_title = 16,panels=FALSE))
```

```{r fig.height=9, fig.width=15}
#| echo: false
diagnostic_plots[[5]] +
  theme(
    plot.subtitle = element_text(size = 16),
    axis.text.x = element_text(size = 10, angle = 45, hjust = 1)
    )
```

Variance inflation diagnostics show **no evidence of multicollinearity** among predictors.

## Key Findings {#key-findings-visualizations}

Model diagnostics indicated that residuals deviate slightly from normality, especially at the tails. While estimates for linear mixed models are generally robust to such deviations, I decided to include **bootstrapped 95% confidence intervals** (CIs) to better capture uncertainty. *Bootstrapping* repeatedly resamples the data (with replacement) to generate a distribution of each estimate, then calculates a confidence interval from this distribution. This approach does not rely on the normality assumption and provides more reliable uncertainty estimates for the fixed effects.

```{r include=FALSE}
boot.res  <- readRDS("output/boot_res.rds")

# Fixed effects of interest
research_effects <- c("poscomp_rookie_c", 
                      "poscomp_soph_c", 
                      "poscomp_rookie_c:ns(CareerYear_c, 2)1", 
                      "poscomp_rookie_c:ns(CareerYear_c, 2)2", 
                      "ns(CareerYear_c, 2)1:poscomp_soph_c", 
                      "ns(CareerYear_c, 2)2:poscomp_soph_c")

indices <- which(names(fixef(fit_mixed)) %in% research_effects)

# 95% CIs
ci_list <- lapply(indices, function(i) {
  quantile(boot.res$t[, i], probs = c(0.025, 0.975))
  })

names(ci_list) <- research_effects
```

```{r}
#| echo: false
#| message: false
#| warning: false
coef_table <- data.frame(
  estimate = fixef(fit_mixed)[research_effects],
  conf.low = sapply(ci_list, `[`,1),
  conf.high = sapply(ci_list, `[`,2)
  ) %>%
  mutate(sig. = ifelse(conf.low * conf.high > 0, "*", " "))

kable(coef_table, digits = 4, caption = "Fixed Effects with Bootstrapped 95% CI") %>%
  kable_styling(full_width = FALSE) 
```

 

Because Career Year is centered, model estimates for career-year effects should be interpreted relative to the average early-career stage in the sample.

A full summary table including estimates for all predictors with bootstrapped confidence intervals is provided in the [Appendix].

#### Interpretation of Spline Terms

Instead of interpreting the numeric coefficients for interactions with spline terms directly, it's more informative to visualize them. The Career Year effect, `ns(CareerYear_c, 2)`, is **decomposed into two natural spline basis functions** (Basis 1 and Basis 2), which can be plotted to show their individual contributions.

```{r}
#| eval: false
#| include: false
# See what knots are selected
attr(terms(fit_mixed), "predvars")[[4]]
```

```{r echo=FALSE}
# Plotting each basis function
career_seq <- seq(min(player_data$CareerYear_c), max(player_data$CareerYear_c), 
                  length.out=100)
basis <- ns(career_seq, knots=0.05487805, Boundary.knots = c(-1.94512195,2.05487805))
matplot(career_seq, basis, type = "l", lty=1, col=c("black","red"), xaxt = "n",
        xlab = "Career Year (uncentered)", ylab = "Basis Function Value",
        main = "Decomposed Spline Basis Functions for Career Year",
        cex.main = 1.2, font.main = 2)
axis(1, at = -2:2, labels = 1:5)
legend("topleft", legend = c("Basis 1", "Basis 2"), col=c("black","red"), lty=1)
```

The estimated interaction between sophomore-year competition and the second spline basis (Basis 2) is -0.183 (95% CI \[-0.31, -0.06\]). Basis 2 captures the accelerating (convex) portion of the Career Year effect; the negative interaction indicates that higher sophomore-year competition dampens that acceleration, so growth that would normally pick up after Year 3 tends to flatten or dip.

## Visualizations

The first plot summarizes the relevant **fixed effects** from the linear mixed-effects model, showing estimates with bootstrapped 95% confidence intervals. The second plot illustrates the **interaction** between sophomore-year competition and Career Year.

### Fixed Effects Plot

```{r echo=FALSE}
coefs_plot <- data.frame(
  term = research_effects,
  estimate = fixef(fit_mixed)[research_effects],
  conf.low = sapply(ci_list, `[`,1),
  conf.high = sapply(ci_list, `[`,2)
  )

coefs_plot <- coefs_plot %>%
  mutate(
    term_type = ifelse(grepl(":", term), "Interaction", "Main Effect"),
    term = dplyr::recode(term,
                         "poscomp_rookie_c" = "Rookie Competition",
                         "poscomp_soph_c" = "Sophomore Competition",
                         "poscomp_rookie_c:ns(CareerYear_c, 2)1" = "Rookie Competition x Career Year (Basis 1)", 
                         "poscomp_rookie_c:ns(CareerYear_c, 2)2" = "Rookie Competition x Career Year (Basis 2)", 
                         "ns(CareerYear_c, 2)1:poscomp_soph_c" = "Sophomore Competition x Career Year (Basis 1)", 
                         "ns(CareerYear_c, 2)2:poscomp_soph_c" = "Sophomore Competition x Career Year (Basis 2)")
    )
desired_order <- c(
   "Sophomore Competition x Career Year (Basis 2)",
  "Sophomore Competition x Career Year (Basis 1)",
  "Sophomore Competition",
  "Rookie Competition x Career Year (Basis 2)",
  "Rookie Competition x Career Year (Basis 1)",
  "Rookie Competition"
)

coefs_plot <- coefs_plot %>%
  mutate(term = factor(term, levels = desired_order))

coefs_plot <- coefs_plot %>%
  mutate(
    tooltip = paste0(
      term, "\nEstimate: ", round(estimate, 2),
      "\n95% CI: [", round(conf.low, 2), ", ", round(conf.high, 2), "]"
    )
  )

p2 <- ggplot(coefs_plot, aes(x = estimate, y = term, color = term_type, text = tooltip)) +
  geom_point(size=3) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height=0.2) +
  geom_vline(xintercept=0, linetype = "dashed", color = "grey50") +
  scale_color_manual(values = c("Main Effect" = "#f0f921", "Interaction" = "#0d0887")) +
  labs(x = "Estimate (with Bootstrapped 95% CI)", y = "",  color = "Term Type",
       title = "Fixed Effects on Points per Game") +
  theme_minimal() +
   theme(
    plot.title = element_text(face = "bold", size=16)
    )

ggplotly(p2, tooltip = "text") %>%
  layout(
    #title = list(
  #  text = "Fixed Effects on Points per Game",
  #  x = 0,  
  #  y = 0.95,
  #  xanchor = "left"
  #),
    legend = list(
    x = 1.02, 
    y = 0.5, 
    xanchor = "left", 
    yanchor = "middle"
    )
  )
```

 

Sophomore-year competition interacts significantly with Career Year, and rookie-year competition has a small positive effect on baseline scoring. While the estimated effects are modest (-0.18 and 0.15), they demonstrate consistent, statistically significant patterns in early-career scoring.

Controlling for other covariates, this suggests that **players with more rookie-year competition have marginally higher baseline scoring** outputs, while **players with higher competition in their sophomore year tend to follow different scoring trajectories** over their first five seasons.

Particularly, players who faced more competitors in their second season show flatter or even negative growth in their scoring output after Year 3 compared to peers with fewer competitors.

### Interaction Plot

To illustrate this effect on scoring trajectory, predicted points per game are shown across the first five career years for different levels of sophomore-year competition. Confidence bands highlight uncertainty in the predictions.

```{r interaction_plot, echo=FALSE}
#| message: false
#| warning: false
int_pred <- ggpredict(fit_mixed, terms = c("CareerYear_c[all]", "poscomp_soph_c"))

# Un-center CareerYear
mean_year <- mean(player_data$CareerYear_index, na.rm = TRUE)
int_pred$career_year <- round(int_pred$x + mean_year,0)

# Map to original poscomp_soph values
orig_soph_levels <- sort(unique(player_data$poscomp_soph))
names(orig_soph_levels) <- sort(unique(int_pred$group)) 

# Create proper labels
labels_soph <- ifelse(orig_soph_levels == 1,
                      paste(orig_soph_levels, "Competitor"),
                      paste(orig_soph_levels, "Competitors"))

levels_soph <- sort(unique(int_pred$group))

int_pred$group <- factor(int_pred$group,
                         levels = levels_soph,
                         labels = labels_soph)

# Interaction plot
p3 <- ggplot(int_pred, aes(x = career_year, y = predicted, color = group, group=group)) +
  geom_line(aes(
    text = paste0(
      "Competition Level: ", group, "<br>",
      "Predicted PTS/G: ", round(predicted, 2), "<br>",
      "95% CI: [", round(conf.low,2), ", ", round(conf.high,2), "]"
    )
  ), linewidth=1.2) +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill="grey70", alpha=0.2,
              show.legend = FALSE) +
  scale_x_continuous(
    breaks = seq(min(int_pred$career_year), max(int_pred$career_year), length.out=5),
    name = "Career Year"
    ) +
  scale_color_viridis(
  discrete = TRUE, 
  name = "Sophomore-Year Competition Level",
  option = "C" 
  ) +
  labs(
    y = "Predicted Points per Game",
    title = "Predicted Scoring Trajectories by Sophomore-Year Competition",
    subtitle = "with Bootstrapped 95% Confidence Intervals"
    ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size=16),
    plot.subtitle = element_text(hjust=0.5, size=12, face = "italic", 
                                 color = "gray40")
    )

ggplotly(p3,tooltip="text")%>%
  layout(
    title = list(
      text = paste0(
        '<b>Predicted Scoring Trajectories by Sophomore-Year Competition</b><br>',
        '<sup style="color:gray">with Bootstrapped 95% Confidence Intervals</sup>'
      ),
      x = 0,
      xanchor = "left"
    ),
    legend = list(
      x=1.02, y=1,
      xanchor = "left", yanchor = "top"
    )
  )
```

 

Predicted scoring trajectories vary non-linearly across career years and differ by sophomore-year competition level. Players facing more competition in their second season tend to have higher predicted points per game in the early years, but these advantages diminish over time, with trajectories converging (or in some cases reversing) by Year 4 or 5.

### Interpretation

Together, the fixed-effects and interaction plots suggest that, controlling for other player- and team-level effects, **sophomore-year positional competition reduces scoring growth after Year 3**. Rookie-year competition, by contrast, has little to no impact on growth trajectories though it has a marginal, positive impact on baseline scoring levels.

While the effect sizes are modest, they highlight the subtle influence of early-career competition, especially in the sophomore season, on a player's scoring trajectory.

## Limitations

There are several limitations to this analysis. First, using fixed position categories is somewhat restrictive as NBA players increasingly have dynamic, position-less roles. Second, focusing only on lottery picks limits generalizability across the league, though it reduces noise from fringe players with irregular output. Third, positional competition is measured based on a simple count of teammates with more experience and similar minutes, which may introduce measurement error and does not capture qualitative differences in teammates' skill levels or roles on the team. Finally, sample sizes are smaller for higher competition groups, so estimates for these groups are less stable.

## Conclusion

This analysis shows that early-career positional competition has a subtle but meaningful impact on scoring trajectories for NBA lottery picks. Players facing more competition in their sophomore year tend to have flatter or even declining scoring growth after Year 3, while rookie-year competition gives a small boost to baseline scoring without noticeably affecting growth.

From a team perspective, these findings could help guide drafting or roster decisions as well as player development. For instance, understanding the overall impact of early-career competition could inform how teams allocate minutes or understand early-career development trends.

Overall, this analysis highlights how mixed-effects modeling can uncover patterns in complex longitudinal sports data.

## Appendix

### Fixed Effects Table

```{r}
#| echo: false
#| message: false
#| warning: false
all_effects <- names(fixef(fit_mixed))

# 95% CIs for all fixed effects
ci_list_all <- lapply(seq_along(all_effects), function(i) {
  quantile(boot.res$t[, i], probs = c(0.025, 0.975))
})

names(ci_list_all) <- all_effects

# Build table
coef_table_all <- data.frame(
  estimate = fixef(fit_mixed),
  conf.low = sapply(ci_list_all, `[`, 1),
  conf.high = sapply(ci_list_all, `[`, 2)
) %>%
  mutate(sig. = ifelse(conf.low * conf.high > 0, "*", " "))

kable(coef_table_all, digits = 4, caption = "Fixed Effects with Bootstrapped 95% CI") %>%
  kable_styling(full_width = FALSE) 
```

------------------------------------------------------------------------

### Model Summary

```{r}
#| echo: false
### Model Information ###
summary(fit_mixed,correlation=FALSE)
```

[**Note**]{.underline}: *Level-1 predictors were not decomposed into within-player and between-player components in this model, as they are control variables. Their estimates should be interpreted as a mix of within- and between-player effects.*

### Code

My code for this analysis can be found here:

[Code](code.qmd){.btn .btn-primary}

```{r}
#| eval: false
#| include: false
saveRDS(fit_mixed, "output/fit_mixed.rds")
saveRDS(boot.res, "output/boot_res.rds")
```
